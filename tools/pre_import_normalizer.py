#!/usr/bin/env python3
"""
–ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç—É –ø–µ—Ä–µ–¥ —ñ–º–ø–æ—Ä—Ç–æ–º –≤ vedavoice.org
–í–∏–ø—Ä–∞–≤–ª—è—î mojibake, –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫—É, —Ç–∞ –∑–∞—Å—Ç–æ—Å–æ–≤—É—î –∞–∫–∞–¥–µ–º—ñ—á–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞ —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—ó
"""

import re
import json
from typing import Dict, List

# ============================================================================
# 1. MOJIBAKE —ñ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ —Å–∏–º–≤–æ–ª–∏
# ============================================================================

MOJIBAKE_REPLACEMENTS = {
    # –ó–Ω–∞–∫–∏ –ø–∏—Ç–∞–Ω–Ω—è –∑–∞–º—ñ—Å—Ç—å –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–∏
    'ÔøΩ': '',  # –í–∏–¥–∞–ª—è—î–º–æ –Ω–µ–≤—ñ–¥–æ–º—ñ —Å–∏–º–≤–æ–ª–∏
    
    # Windows-1252 ‚Üí UTF-8
    '√¢‚Ç¨‚Ñ¢': "'",  # right single quotation mark
    '√¢‚Ç¨≈ì': '"',  # left double quotation mark
    '√¢‚Ç¨': '"',  # right double quotation mark
    '√¢‚Ç¨"': '‚Äî',  # em dash
    '√¢‚Ç¨"': '‚Äì',  # en dash
    
    # –ü–æ–¥–≤—ñ–π–Ω—ñ –∞–ø–æ—Å—Ç—Ä–æ—Ñ–∏
    "''": "'",
    '``': '"',
    
    # –Ü–Ω—à—ñ –ø–æ–º–∏–ª–∫–∏ –∫–æ–¥—É–≤–∞–Ω–Ω—è
    '√É¬°': '√°',
    '√É¬©': '√©',
    '√É¬≠': '√≠',
    '√É¬≥': '√≥',
    '√É¬∫': '√∫',
    
    # –î–û–î–ê–¢–ö–û–í–Ü –∑ textNormalizer.ts
    '\ufeff': '',  # BOM (byte order mark)
    '\u00A0': ' ',  # non-breaking space
    '\u2018': "'",  # left single quotation mark
    '\u2019': "'",  # right single quotation mark
    '\u201C': '"',  # left double quotation mark
    '\u201D': '"',  # right double quotation mark
    '\u2013': '-',  # en dash
    '\u2014': '‚Äî',  # em dash
    '\r\n': '\n',   # Windows line endings
    '\r': '\n',     # Mac line endings
    '\t': ' ',      # tabs to spaces
}

# ============================================================================
# 2. –î—ñ–∞–∫—Ä–∏—Ç–∏—á–Ω—ñ —Å–∏–º–≤–æ–ª–∏ (—Å–∞–Ω—Å–∫—Ä–∏—Ç ‚Üí —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞ —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—è)
# ============================================================================

DIACRITIC_FIXES = {
    # –î–æ–≤–≥—ñ –≥–æ–ª–æ—Å–Ω—ñ
    'ƒÅ': '–∞ÃÑ',
    'ƒ´': 'ƒ±ÃÑ',  # ƒ´ ‚Üí ƒ±ÃÑ (–ª–∞—Ç–∏–Ω—Å—å–∫–∞ dotless i + –º–∞–∫—Ä–æ–Ω, –ë–ï–ó –∫—Ä–∞–ø–∫–∏!)
    '≈´': '”Ø',
    '·πù': '—ÄÃ£ÃÑ',
    
    # –†–µ—Ç—Ä–æ—Ñ–ª–µ–∫—Å–Ω—ñ –ø—Ä–∏–≥–æ–ª–æ—Å–Ω—ñ
    '·π≠': '—ÇÃ£',
    '·∏ç': '–¥Ã£',
    '·πá': '–ΩÃ£',
    '·π£': '—à',
    '·πõ': '—ÄÃ£',
    
    # –ü–∞–ª–∞—Ç–∞–ª—å–Ω—ñ —Ç–∞ —ñ–Ω—à—ñ
    '≈õ': '—àÃÅ',
    '√±': '–ΩÃÉ',
    '·πÖ': '–ΩÃá',
    '·πÅ': '–ºÃá',
    '·∏•': '—ÖÃ£',

    # ‚ùå –í–ò–î–ê–õ–ï–ù–û –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –¥—ñ–∞–∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –∫—Ä–∞–ø–æ–∫
    # Gitabase –ø–æ–≤–µ—Ä—Ç–∞—î —á–∏—Å—Ç–∏–π —Ç–µ–∫—Å—Ç –∑ HTML, –±–µ–∑ –ø–æ–º–∏–ª–æ–∫ –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–∏
    # –ü—Ä–∞–≤–∏–ª–∞ —Ç–∏–ø—É '–∞Ã£': '–∞' –ø—Å—É—é—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—É —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—é (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥ —á–∞—Ä–∞–ΩÃ£–∞ ‚Üí —á–∞—Ä–∞–Ω–∞)
}

# ============================================================================
# 3. –°–ª–æ–≤–Ω–∏–∫–∏ –∑–∞–º—ñ–Ω –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –≤–µ—Ä—Å—ñ—ó
# ============================================================================
# –ù–∞ –æ—Å–Ω–æ–≤—ñ –∑–∞—Ç–≤–µ—Ä–¥–∂–µ–Ω–æ–≥–æ —Å–ø–∏—Å–∫—É —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—ó/—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó
# –ü—Ä–∞–≤–∏–ª–æ: –∑–∞–º—ñ–Ω—é—î–º–æ –¶–Ü–õ–Ü –°–õ–û–í–ê, –Ω–µ –æ–∫—Ä–µ–º—ñ —Å–∏–º–≤–æ–ª–∏
# –ê–ø–æ—Å—Ç—Ä–æ—Ñ ' –∑–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç–∞–º, –¥–µ –≤—ñ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π (–∞—á–∞—Ä'—è, –∞–Ω—Ç–∞—Ä'—è–º—ñ)

WORD_REPLACEMENTS = {
    # =========================
    # –û–°–ù–û–í–ù–Ü –Ü–ú–ï–ù–ê (–ø—Ä–∞–≤–∏–ª—å–Ω–∞ —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—è)
    # =========================
    
    # –ß–∞–π—Ç–∞–Ω—å—è (–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –ø—ñ—Å–ª—è —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—ó: –Ω–π–∞ ‚Üí –Ω—å—è)
    "–®—Ä—ñ –ß–∞–π—Ç–∞–Ω'—è-—á–∞—Ä—ñ—Ç–∞–º—Ä—ñ—Ç–∞": "–®—Ä—ñ –ß–∞–π—Ç–∞–Ω—å—è-—á–∞—Ä—ñ—Ç–∞–º—Ä—ñ—Ç–∞",
    "–ß–∞–π—Ç–∞–Ω'—è-—á–∞—Ä—ñ—Ç–∞–º—Ä—ñ—Ç–∞": "–ß–∞–π—Ç–∞–Ω—å—è-—á–∞—Ä—ñ—Ç–∞–º—Ä—ñ—Ç–∞",
    "–ß–∞–π—Ç–∞–Ω'—è-—á–∞–Ω–¥—Ä–æ–¥–∞—è-–Ω–∞—Ç–∞–∫–∞": "–ß–∞–π—Ç–∞–Ω—å—è-—á–∞–Ω–¥—Ä–æ–¥–∞—è-–Ω–∞—Ç–∞–∫–∞",
    "–ß–∞–π—Ç–∞–Ω'—è-–±–≥–∞“ë–∞–≤–∞—Ç–∞": "–ß–∞–π—Ç–∞–Ω—å—è-–±–≥–∞“ë–∞–≤–∞—Ç–∞",
    "–ß–∞–π—Ç–∞–Ω'—è": "–ß–∞–π—Ç–∞–Ω—å—è",
    "–ß–∞–π—Ç–∞–Ω'—ó": "–ß–∞–π—Ç–∞–Ω—å—ó",
    "–ß–∞–π—Ç–∞–Ω'—é": "–ß–∞–π—Ç–∞–Ω—å—é",
    "–ß–∞–π—Ç–∞–Ω'—î—é": "–ß–∞–π—Ç–∞–Ω—å—î—é",
    # –ù–û–í–Ü –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—ó –Ω–π–∞ ‚Üí –Ω—å—è
    "—á–∞—ñ—Ç–∞–Ω–π–∞": "–ß–∞–π—Ç–∞–Ω—å—è",
    "–ß–∞—ñ—Ç–∞–Ω–π–∞": "–ß–∞–π—Ç–∞–Ω—å—è",
    "—á–∞—ñ—Ç–∞–Ω–π—ñ": "–ß–∞–π—Ç–∞–Ω—å—ó",
    "—á–∞—ñ—Ç–∞–Ω–π—É": "–ß–∞–π—Ç–∞–Ω—å—é",
    
    # –ù—ñ—Ç—å—è–Ω–∞–Ω–¥–∞ (–∞–ø–æ—Å—Ç—Ä–æ—Ñ ' ‚Üí –º'—è–∫–∏–π –∑–Ω–∞–∫ —å)
    "–ù—ñ—Ç'—è–Ω–∞–Ω–¥–∞": "–ù—ñ—Ç—å—è–Ω–∞–Ω–¥–∞",
    "–ù—ñ—Ç'—è–Ω–∞–Ω–¥–∏": "–ù—ñ—Ç—å—è–Ω–∞–Ω–¥–∏",
    "–ù—ñ—Ç'—è–Ω–∞–Ω–¥—ñ": "–ù—ñ—Ç—å—è–Ω–∞–Ω–¥—ñ",
    "–ù—ñ—Ç'—è–Ω–∞–Ω–¥—É": "–ù—ñ—Ç—å—è–Ω–∞–Ω–¥—É",
    "–ù—ñ—Ç'—è–Ω–∞–Ω–¥–æ—é": "–ù—ñ—Ç—å—è–Ω–∞–Ω–¥–æ—é",
    
    "–ú–∞—Ö–∞–ø—Ä–∞–±—Ö—É": "–ú–∞—Ö–∞–ø—Ä–∞–±–≥—É",
    
    # “ê–æ–ø—ñ–Ω–∞—Ç–≥–∞ ‚Üí “ê–æ–ø—ñ–Ω–∞—Ç—Ö–∞
    "“ê–æ–ø—ñ–Ω–∞—Ç–≥–∞": "“ê–æ–ø—ñ–Ω–∞—Ç—Ö–∞",
    "“ê–æ–ø—ñ–Ω–∞—Ç–≥—É": "“ê–æ–ø—ñ–Ω–∞—Ç—Ö—É",
    
    # –ï–Ω–µ—Ä–≥—ñ—è (“ë ‚Üí –≥, –ø—Ä–∞–≤–∏–ª—å–Ω–æ –±–µ–∑ “ë)
    "–µ–Ω–µ—Ä“ë—ñ—è": "–µ–Ω–µ—Ä–≥—ñ—è",
    "–µ–Ω–µ—Ä“ë—ñ—ó": "–µ–Ω–µ—Ä–≥—ñ—ó",
    "–µ–Ω–µ—Ä“ë—ñ—é": "–µ–Ω–µ—Ä–≥—ñ—é",
    "–µ–Ω–µ—Ä“ë—ñ—î—é": "–µ–Ω–µ—Ä–≥—ñ—î—é",
    "–µ–Ω–µ—Ä“ë—ñ—è–º–∏": "–µ–Ω–µ—Ä–≥—ñ—è–º–∏",
    
    # –°–∞–Ω–Ω—å—è—Å—ñ (—Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–µ –ø—Ä–∞–≤–∏–ª–æ –∑ SQL —Ñ—É–Ω–∫—Ü—ñ—ó)
    "—Å–∞–Ω–Ω'—è—Å—ñ": "—Å–∞–Ω–Ω—å—è—Å—ñ",
    "–°–∞–Ω–Ω'—è—Å—ñ": "–°–∞–Ω–Ω—å—è—Å—ñ",
    "—Å–∞–Ω–Ω'—è—Å–∞": "—Å–∞–Ω—å—è—Å–∞",
    "–°–∞–Ω–Ω'—è—Å–∞": "–°–∞–Ω—å—è—Å–∞",
    "—Å–∞–Ω–Ω'—è—Å—É": "—Å–∞–Ω—å—è—Å—É",
    "—Å–∞–Ω–Ω'—è—Å–æ—é": "—Å–∞–Ω—å—è—Å–æ—é",
    "—Å–∞–Ω–Ω'—è—Å–∞–º": "—Å–∞–Ω—å—è—Å–∞–º",
    "—Å–∞–Ω–Ω'—è—Å–∞–º–∏": "—Å–∞–Ω—å—è—Å–∞–º–∏",
    
    # –°–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è
    "–ø—Ä–æ–¥–∂–¥–∂–≥—ñ—Ç–∞": "–ø—Ä–æ–¥–∂–¥–∂—Ö—ñ—Ç–∞",
    "–ü—Ä–æ–¥–∂–¥–∂–≥—ñ—Ç–∞": "–ü—Ä–æ–¥–∂–¥–∂—Ö—ñ—Ç–∞",
    
    # –î–û–î–ê–¢–ö–û–í–Ü –∑ textNormalizer.ts
    "–ê—á–π—É—Ç–∞": "–ê—á—å—é—Ç–∞",
    "–ê–¥–≤–∞–π—Ç–∞": "–ê–¥–≤–∞—ñ—Ç–∞",
    "–î–∂–≥–∞—Ä—ñ–∫—Ö–∞–Ω–¥–∞": "–î–∂—Ö–∞—Ä—ñ–∫—Ö–∞–Ω–¥–∞",
    
    # –Ü–Ω—à—ñ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –ø—Ä–∏–¥–∏—Ö–æ–≤–∏—Ö
    "–ü—É—Ä—É—à–∏": "–ü—É—Ä—É—à–∏",  # —è–∫—â–æ –±—É–ª–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–æ–≤–∞–Ω–æ
}

# ============================================================================
# 4. –í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—ó (bh‚Üí–±–≥, th‚Üí—Ç—Ö, —Ç–æ—â–æ)
# ============================================================================

TRANSLIT_FIXES = {
    # –ü—Ä–∏–¥–∏—Ö–æ–≤—ñ –ø—Ä–∏–≥–æ–ª–æ—Å–Ω—ñ (h –ø—ñ—Å–ª—è –ø—Ä–∏–≥–æ–ª–æ—Å–Ω–æ—ó)
    "–±—Ö": "–±–≥",
    "–ë—Ö": "–ë–≥",
    "–ë–•": "–ë–ì",
    
    "“ë—Ö": "“ë–≥",
    "“ê—Ö": "“ê–≥",
    
    "–¥—Ö": "–¥–≥",
    "–î—Ö": "–î–≥",
    
    "—Ç–≥": "—Ç—Ö",
    "–¢–≥": "–¢—Ö",
    
    "–∫–≥": "–∫—Ö",
    "–ö–≥": "–ö—Ö",
    
    "—á–≥": "—á—Ö",
    "–ß–≥": "–ß—Ö",
    
    # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ –∑ Gitabase
    "–ø–≥": "–ø—Ö",
    "–ü–≥": "–ü—Ö",
    
    # –î–û–î–ê–¢–ö–û–í–Ü –ü–†–ê–í–ò–õ–ê –∑ normalize_ukrainian_cc_texts (SQL —Ñ—É–Ω–∫—Ü—ñ—è)
    # –ü—Ä–∏–¥–∏—Ö–æ–≤—ñ –ø—Ä–∏–≥–æ–ª–æ—Å–Ω—ñ (—Å–∫–ª–∞–¥–Ω—ñ –≤–∏–ø–∞–¥–∫–∏)
    "–¥–∂–≥": "–¥–∂—Ö",
    "–î–∂–≥": "–î–∂—Ö",
    "–¥–∂–¥–∂–≥": "–¥–∂–¥–∂—Ö",
    "–î–∂–¥–∂–≥": "–î–∂–¥–∂—Ö",
}

# ============================================================================
# 5. –°–ø–æ–ª—É—á–µ–Ω–Ω—è –ø—Ä–∏–≥–æ–ª–æ—Å–Ω–∏—Ö (–∞–∫–∞–¥–µ–º—ñ—á–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞)
# ============================================================================

CONSONANT_CLUSTERS = {
    # –ó –ø—Ä–∞–≤–∏–ª —Å–∞–Ω—Å–∫—Ä–∏—Ç‚Üí—É–∫—Ä–∞—ó–Ω—Å—å–∫–∞
    "k·π£": "–∫—à",
    "·πÖg": "–ΩÃá“ë",
    "√±i": "–ΩÃÉ—ñ",
    "·πõ·π£·πá": "—ÄÃ£—à–ΩÃ£",
    "hy": "—Ö–π",
    "ye": "–π–µ",
    "ya": "–π–∞",
    "aya": "–∞–π–∞",
    "ƒÅye": "–∞ÃÑ–π–µ",
    "jjh": "–∂–¥–∂—Ö",
    # ‚ùå –í–ò–î–ê–õ–ï–ù–û "jh": "–∂—Ö" - –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—É—î –∑ convert_english_to_ukrainian_translit
}

# ============================================================================
# 6. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—ó —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—ó ‚Üí —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞
# ============================================================================

ENGLISH_TO_UKRAINIAN_TRANSLIT = {
    # –ü—Ä–∏–≥–æ–ª–æ—Å–Ω—ñ
    'kh': '–∫—Ö',
    'gh': '“ë–≥',
    'ch': '—á',
    'jh': '–¥–∂—Ö',
    'th': '—Ç—Ö',
    'dh': '–¥–≥',
    'ph': '–ø—Ö',
    'bh': '–±–≥',
    
    # –ü–∞–ª–∞—Ç–∞–ª—å–Ω—ñ
    '≈õ': '—àÃÅ',
    'sh': '—Å—Ö',
    '·π£': '—à',
    
    # –†–µ—Ç—Ä–æ—Ñ–ª–µ–∫—Å–Ω—ñ
    '·π≠': '—ÇÃ£',
    '·∏ç': '–¥Ã£',
    '·πá': '–ΩÃ£',
    '·πõ': '—ÄÃ£',
    
    # –Ü–Ω—à—ñ
    '√±': '–ΩÃÉ',
    '·πÖ': '–ΩÃá',
    '·πÅ': '–ºÃá',
    '·∏•': '—ÖÃ£',
    
    # –ì–æ–ª–æ—Å–Ω—ñ
    'ƒÅ': '–∞ÃÑ',
    'ƒ´': 'ƒ±ÃÑ',  # ƒ´ ‚Üí ƒ±ÃÑ (–ª–∞—Ç–∏–Ω—Å—å–∫–∞ dotless i + –º–∞–∫—Ä–æ–Ω, –ë–ï–ó –∫—Ä–∞–ø–∫–∏!)
    '≈´': '”Ø',
    'ai': '–∞—ñ',
    'au': '–∞—É',
    
    # –ü—Ä–æ—Å—Ç—ñ –ø—Ä–∏–≥–æ–ª–æ—Å–Ω—ñ
    'k': '–∫',
    'g': '“ë',
    'c': '—á',
    'j': '–¥–∂',
    't': '—Ç',
    'd': '–¥',
    'p': '–ø',
    'b': '–±',
    'y': '–π',
    'r': '—Ä',
    'l': '–ª',
    'v': '–≤',
    'w': '–≤',
    'h': '—Ö',
    'm': '–º',
    'n': '–Ω',
    's': '—Å',
    
    # –ü—Ä–æ—Å—Ç—ñ –≥–æ–ª–æ—Å–Ω—ñ
    'a': '–∞',
    'i': '—ñ',
    'u': '—É',
    'e': '–µ',
    'o': '–æ',
}

def convert_english_to_ukrainian_translit(text: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î –∞–Ω–≥–ª—ñ–π—Å—å–∫—É IAST —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—é —Å–∞–Ω—Å–∫—Ä–∏—Ç—É –≤ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É
    –∑–∞ –∞–∫–∞–¥–µ–º—ñ—á–Ω–∏–º–∏ –ø—Ä–∞–≤–∏–ª–∞–º–∏
    
    –ü—Ä–∏–∫–ª–∞–¥: 'vande gur≈´n ƒ´≈õa-bhaktƒÅn' ‚Üí '–≤–∞–Ω–¥–µ “ë—É—Ä”Ø–Ω ƒ´—à–∞-–±–≥–∞–∫—ÇƒÅ–Ω'
    
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –∞–ª–≥–æ—Ä–∏—Ç–º –ñ–ê–î–Ü–ë–ù–û–ì–û –ó–ë–Ü–ì–£ (greedy matching):
    –π–¥–µ –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ, —à—É–∫–∞—î –Ω–∞–π–¥–æ–≤—à–∏–π –ø—ñ–¥—Ä—è–¥–æ–∫ —â–æ –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑ –ø–æ—Ç–æ—á–Ω–æ—ó –ø–æ–∑–∏—Ü—ñ—ó
    """
    if not text:
        return text
    
    # –°–ø–æ—á–∞—Ç–∫—É –≤–∏–¥–∞–ª—è—î–º–æ "Verse text" —è–∫—â–æ —î
    text = text.replace('Verse text ', '').replace('Verse Text ', '')
    
    # –ú–∞–ø–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó (–¥–æ–≤–∂–∏–Ω–∞ ‚Üí —Å–ø–∏—Å–æ–∫ —à–∞–±–ª–æ–Ω—ñ–≤)
    # –ö–†–ò–¢–ò–ß–ù–û: —Å–æ—Ä—Ç—É—î–º–æ –∑–∞ –¥–æ–≤–∂–∏–Ω–æ—é —Å–ø–∞–¥–Ω–æ –¥–ª—è –∂–∞–¥—ñ–±–Ω–æ–≥–æ –∑–±—ñ–≥—É
    patterns = {
        # 3 —Å–∏–º–≤–æ–ª–∏
        'cch': '—á—á—Ö', 'jjh': '–∂–¥–∂—Ö','k·π£a': '–∫—à–∞', 'k·π£e': '–∫—à–µ', 'k·π£i': '–∫—à—ñ', 'k·π£u': '–∫—à—É', 'k·π£·πá': '–∫—à–ΩÃ£',
        'aya': '–∞–π–∞', 'aye': '–∞–π–µ', 'hye': '—Ö–π–µ',
        'K·π£a': '–∫—à–∞', 'K·π£e': '–∫—à–µ', 'K·π£i': '–∫—à—ñ', 'K·π£u': '–∫—à—É',
        # –°–ø–æ–ª—É—á–µ–Ω–Ω—è ny + –≥–æ–ª–æ—Å–Ω—ñ (–ü–†–ê–í–ò–õ–¨–ù–û: –Ω–π, –∞ –Ω–µ –Ω—å!)
        # –ü—Ä–∏–∫–ª–∞–¥: caitanya ‚Üí —á–∞—ñ—Ç–∞–Ω–π–∞ (–Ω–µ —á–∞—ñ—Ç–∞–Ω—å—è!)
        'nya': '–Ω–π–∞', 'nye': '–Ω–π–µ', 'nyi': '–Ω–π—ñ', 'nyo': '–Ω–π–æ', 'nyu': '–Ω–π—É',
        
        # 2 —Å–∏–º–≤–æ–ª–∏ (–¥—ñ–≥—Ä–∞—Ñ–∏ —Ç–∞ —Å–ø–æ–ª—É—á–µ–Ω–Ω—è)
        'bh': '–±–≥', 'gh': '“ë–≥', 'dh': '–¥–≥', 'th': '—Ç—Ö', 'ph': '–ø—Ö',
        'kh': '–∫—Ö', 'ch': '—á—Ö', 'jh': '–¥–∂—Ö', 'sh': '—Å—Ö',
        'k·π£': '–∫—à', 'j√±': '–¥–∂–ΩÃÉ',
        'ai': '–∞—ñ', 'au': '–∞—É',
        
        # 1 —Å–∏–º–≤–æ–ª –¥—ñ–∞–∫—Ä–∏—Ç–∏—á–Ω—ñ
        '·π£': '—à', '≈õ': '—àÃÅ', '·π≠': '—ÇÃ£', '·∏ç': '–¥Ã£', '·πá': '–ΩÃ£',
        '·πõ': '—ÄÃ£', '√±': '–ΩÃÉ', '·πÖ': '–ΩÃá', '·πÅ': '–ºÃá', '·∏•': '—ÖÃ£',
        
        # 1 —Å–∏–º–≤–æ–ª –¥–æ–≤–≥—ñ –≥–æ–ª–æ—Å–Ω—ñ (+ –≤–µ–ª–∏–∫—ñ –¥–ª—è –ø–æ—á–∞—Ç–∫—É —Ä–µ—á–µ–Ω—å)
        'ƒÅ': '–∞ÃÑ', 'ƒ´': 'ƒ±ÃÑ', '≈´': '”Ø', '·πù': '—ÄÃ£ÃÑ',  # ƒ´ ‚Üí ƒ±ÃÑ (dotless i + –º–∞–∫—Ä–æ–Ω)
        'ƒÄ': '–∞ÃÑ', 'ƒ™': 'ƒ™', '≈™': '”Ø', '·πú': '—ÄÃ£ÃÑ',  # ƒ™ ‚Üí ƒ™ (–≤–µ–ª–∏–∫–∞ –±–µ–∑ –∫—Ä–∞–ø–∫–∏)
        
        # 1 —Å–∏–º–≤–æ–ª –ø—Ä–æ—Å—Ç—ñ –ø—Ä–∏–≥–æ–ª–æ—Å–Ω—ñ (+ –≤–µ–ª–∏–∫—ñ –¥–ª—è –ø–æ—á–∞—Ç–∫—É —Ä–µ—á–µ–Ω—å)
        'k': '–∫', 'g': '“ë', 'c': '—á', 'j': '–¥–∂',
        't': '—Ç', 'd': '–¥', 'p': '–ø', 'b': '–±',
        'y': '–π', 'r': '—Ä', 'l': '–ª', 'v': '–≤',
        'w': '–≤', 'h': '—Ö', 'm': '–º', 'n': '–Ω', 's': '—Å',
        'K': '–∫', 'G': '“ë', 'C': '—á', 'J': '–¥–∂',
        'T': '—Ç', 'D': '–¥', 'P': '–ø', 'B': '–±',
        'Y': '–π', 'R': '—Ä', 'L': '–ª', 'V': '–≤',
        'W': '–≤', 'H': '—Ö', 'M': '–º', 'N': '–Ω', 'S': '—Å',
        
        # 1 —Å–∏–º–≤–æ–ª –ø—Ä–æ—Å—Ç—ñ –≥–æ–ª–æ—Å–Ω—ñ (+ –≤–µ–ª–∏–∫—ñ –¥–ª—è –ø–æ—á–∞—Ç–∫—É —Ä–µ—á–µ–Ω—å)
        'a': '–∞', 'i': '—ñ', 'u': '—É', 'e': '–µ', 'o': '–æ',
        'A': '–∞', 'I': '—ñ', 'U': '—É', 'E': '–µ', 'O': '–æ',
    }
    
    result = []
    i = 0
    
    while i < len(text):
        # –ü—Ä–æ–±—É—î–º–æ –Ω–∞–π–¥–æ–≤—à—ñ –ø—ñ–¥—Ä—è–¥–∫–∏ –ø–µ—Ä—à–∏–º–∏ (3, –ø–æ—Ç—ñ–º 2, –ø–æ—Ç—ñ–º 1)
        matched = False
        
        for length in [3, 2, 1]:
            if i + length <= len(text):
                substr = text[i:i+length]
                if substr in patterns:
                    result.append(patterns[substr])
                    i += length
                    matched = True
                    break
        
        if not matched:
            # –°–∏–º–≤–æ–ª –Ω–µ –≤ –º–∞–ø—ñ (–¥–µ—Ñ—ñ—Å, –ø—Ä–æ–±—ñ–ª, –ª–∞–ø–∫–∏) - –∑–∞–ª–∏—à–∞—î–º–æ —è–∫ —î
            result.append(text[i])
            i += 1
    
    return ''.join(result)


# ============================================================================
# –§–£–ù–ö–¶–Ü–á –ù–û–†–ú–ê–õ–Ü–ó–ê–¶–Ü–á
# ============================================================================

def normalize_mojibake(text: str) -> str:
    """–í–∏–ø—Ä–∞–≤–ª—è—î mojibake —Ç–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ —Å–∏–º–≤–æ–ª–∏"""
    if not text:
        return text
    
    result = text
    for old, new in MOJIBAKE_REPLACEMENTS.items():
        result = result.replace(old, new)
    
    return result


def normalize_diacritics(text: str) -> str:
    """–í–∏–ø—Ä–∞–≤–ª—è—î –¥—ñ–∞–∫—Ä–∏—Ç–∏—á–Ω—ñ —Å–∏–º–≤–æ–ª–∏"""
    if not text:
        return text
    
    result = text
    for old, new in DIACRITIC_FIXES.items():
        result = result.replace(old, new)
    
    return result


def normalize_word_replacements(text: str) -> str:
    """–ó–∞—Å—Ç–æ—Å–æ–≤—É—î —Å–ª–æ–≤–Ω–∏–∫–æ–≤—ñ –∑–∞–º—ñ–Ω–∏"""
    if not text:
        return text
    
    result = text
    for old, new in WORD_REPLACEMENTS.items():
        result = result.replace(old, new)
    
    return result


def normalize_transliteration(text: str) -> str:
    """–í–∏–ø—Ä–∞–≤–ª—è—î —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—é (bh‚Üí–±–≥, —Ç–æ—â–æ)"""
    if not text:
        return text
    
    result = text
    
    # –°–ø–æ—á–∞—Ç–∫—É —Å–ø–æ–ª—É—á–µ–Ω–Ω—è
    for old, new in CONSONANT_CLUSTERS.items():
        result = result.replace(old, new)
    
    # –ü–æ—Ç—ñ–º –æ–∫—Ä–µ–º—ñ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è
    for old, new in TRANSLIT_FIXES.items():
        result = result.replace(old, new)
    
    return result


def normalize_apostrophe_after_n(text: str) -> str:
    """
    –ó–∞–º—ñ–Ω—é—î –∞–ø–æ—Å—Ç—Ä–æ—Ñ –ø—ñ—Å–ª—è "–Ω" –Ω–∞ –º'—è–∫–∏–π –∑–Ω–∞–∫ "—å"
    –ó–∞ –≤–∏–Ω—è—Ç–∫–æ–º –≤–∏–ø–∞–¥–∫—ñ–≤ –¥–µ –∞–ø–æ—Å—Ç—Ä–æ—Ñ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π (–∞—á–∞—Ä'—è, –∞–Ω—Ç–∞—Ä'—è–º—ñ)
    
    –ü—Ä–∞–≤–∏–ª–æ –∑ SQL —Ñ—É–Ω–∫—Ü—ñ—ó normalize_ukrainian_cc_texts:
    –Ω' ‚Üí –Ω—å (–∫—Ä—ñ–º –≤–∏–ø–∞–¥–∫—ñ–≤ –¥–µ –∞–ø–æ—Å—Ç—Ä–æ—Ñ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π)
    """
    if not text:
        return text
    
    # –í–∏–∫–ª—é—á–µ–Ω–Ω—è - —Å–ª–æ–≤–∞ –¥–µ –∞–ø–æ—Å—Ç—Ä–æ—Ñ –ø—ñ—Å–ª—è –Ω –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π
    exceptions = [
        "–∞—á–∞—Ä'—è", "–ê—á–∞—Ä'—è",
        "–∞–Ω—Ç–∞—Ä'—è–º—ñ", "–ê–Ω—Ç–∞—Ä'—è–º—ñ",
        "–∞–Ω—Ç–∞—Ä'—è–º", "–ê–Ω—Ç–∞—Ä'—è–º",
        # –î–æ–¥–∞–π—Ç–µ —ñ–Ω—à—ñ –≤–∏–∫–ª—é—á–µ–Ω–Ω—è —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
    ]
    
    result = text
    
    # –ó–∞–º—ñ–Ω—é—î–º–æ –Ω' –Ω–∞ –Ω—å (case-insensitive –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ä–µ–≥—ñ—Å—Ç—Ä—ñ–≤)
    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ regex –¥–ª—è —Ç–æ—á–Ω—ñ—à–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—é
    import re
    
    # –°–ø–æ—á–∞—Ç–∫—É –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –≤–∏–∫–ª—é—á–µ–Ω–Ω—è (–∑–∞–º—ñ–Ω—è—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–º placeholder)
    placeholders = {}
    for idx, exception in enumerate(exceptions):
        placeholder = f"__EXCEPTION_{idx}__"
        if exception in result:
            placeholders[placeholder] = exception
            result = result.replace(exception, placeholder)
    
    # –¢–µ–ø–µ—Ä —Ä–æ–±–∏–º–æ –∑–∞–º—ñ–Ω—É –Ω' ‚Üí –Ω—å
    result = result.replace("–Ω'", "–Ω—å")
    result = result.replace("–ù'", "–ù—å")
    
    # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –≤–∏–∫–ª—é—á–µ–Ω–Ω—è
    for placeholder, original in placeholders.items():
        result = result.replace(placeholder, original)
    
    return result


def normalize_sanskrit_line_breaks(text: str) -> str:
    """–î–æ–¥–∞—î –ø—Ä–∞–≤–∏–ª—å–Ω—ñ —Ä–æ–∑—Ä–∏–≤–∏ —Ä—è–¥–∫—ñ–≤ —É —Å–∞–Ω—Å–∫—Ä–∏—Ç—ñ/–±–µ–Ω–≥–∞–ª—ñ –∑–∞ –¥–∞–Ω–¥–∞–º–∏.
    
    –§–æ—Ä–º–∞—Ç:
    - –ü–µ—Ä—à–∏–π —Ä—è–¥–æ–∫: –¥–æ ‡•§ (single da·πá·∏ça)
    - –î—Ä—É–≥–∏–π —Ä—è–¥–æ–∫: –ø—ñ—Å–ª—è ‡•§ –¥–æ ‡•• (double da·πá·∏ça –∑ –Ω–æ–º–µ—Ä–æ–º –≤—ñ—Ä—à—É)
    
    –ü—Ä–∏–∫–ª–∞–¥:
    –î–û:  ‡¶¨‡¶®‡ßç‡¶¶‡ßá ‡¶ó‡ßÅ‡¶∞‡ßÇ‡¶®‡ßç‚Äå ‡•§ ‡¶§‡ßé‡¶™‡ßç‡¶∞‡¶ï‡¶æ‡¶∂‡¶æ‡¶Ç‡¶∂‡ßç‡¶ö ‡•• ‡ßß ‡••
    –ü–Ü–°–õ–Ø: ‡¶¨‡¶®‡ßç‡¶¶‡ßá ‡¶ó‡ßÅ‡¶∞‡ßÇ‡¶®‡ßç‚Äå ‡•§\n‡¶§‡ßé‡¶™‡ßç‡¶∞‡¶ï‡¶æ‡¶∂‡¶æ‡¶Ç‡¶∂‡ßç‡¶ö ‡•• ‡ßß ‡••
    """
    if not text:
        return text
    
    # –í–∏–¥–∞–ª—è—î–º–æ —ñ—Å–Ω—É—é—á—ñ \n —â–æ–± –ø–æ—á–∞—Ç–∏ –∑ —á–∏—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç—É
    text = text.replace('\n', ' ')
    
    # –í–∏–¥–∞–ª—è—î–º–æ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏
    text = re.sub(r'\s+', ' ', text).strip()
    
    # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —Ä—è–¥–∫–∏ –∑–∞ ‡•§ (single da·πá·∏ça)
    # –§–æ—Ä–º–∞—Ç: "—Ç–µ–∫—Å—Ç ‡•§ —Ç–µ–∫—Å—Ç ‡•• N ‡••"
    # –í–ê–ñ–õ–ò–í–û: –∑–±–µ—Ä—ñ–≥–∞—î–º–æ ‡•§ –≤ –∫—ñ–Ω—Ü—ñ –ø–µ—Ä—à–æ–≥–æ —Ä—è–¥–∫–∞
    if '‡•§' in text:
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –ü–ï–†–®–£ single da·πá·∏ça (–º–æ–∂–µ –±—É—Ç–∏ –∫—ñ–ª—å–∫–∞ –≤ –¥–æ–≤–≥–∏—Ö –≤—ñ—Ä—à–∞—Ö)
        parts = text.split('‡•§', 1)  # Split –Ω–∞ 2 —á–∞—Å—Ç–∏–Ω–∏
        if len(parts) == 2:
            first_line = parts[0].strip() + ' ‡•§'
            second_line = parts[1].strip()
            return f'{first_line}\n{second_line}'
    
    return text


def remove_gitabase_artifacts(text: str) -> str:
    """–í–∏–¥–∞–ª—è—î –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∏ Gitabase (–Ω–æ–º–µ—Ä–∏ –≤—ñ—Ä—à—ñ–≤, –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏)"""
    if not text:
        return text
    
    # –í–∏–¥–∞–ª—è—î–º–æ "–¢–µ–∫—Å—Ç 1:", "18:" –Ω–∞ –ø–æ—á–∞—Ç–∫—É
    result = re.sub(r'^\s*\d+\s*:\s*', '', text)
    result = re.sub(r'^\s*–¢–µ–∫—Å—Ç\s+\d+\s*:\s*', '', text, flags=re.IGNORECASE)
    
    # –ú–Ω–æ–∂–∏–Ω–Ω—ñ –ø—Ä–æ–±—ñ–ª–∏ ‚Üí –æ–¥–∏–Ω –ø—Ä–æ–±—ñ–ª
    result = re.sub(r'\s+', ' ', result)
    
    # –í–∏–¥–∞–ª—è—î–º–æ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏ –Ω–∞–≤–∫–æ–ª–æ –∑–Ω–∞–∫—ñ–≤ –ø—É–Ω–∫—Ç—É–∞—Ü—ñ—ó
    result = re.sub(r'\s+([,.;:!?])', r'\1', result)
    
    return result.strip()


def convert_synonyms_from_english(synonyms_en: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î synonyms_en ‚Üí synonyms_uk
    
    –û–±—Ä–æ–±–ª—è—î —Ç—ñ–ª—å–∫–∏ —Å–∞–Ω—Å–∫—Ä–∏—Ç—Å—å–∫—ñ/–±–µ–Ω–≥–∞–ª—å—Å—å–∫—ñ —Ç–µ—Ä–º—ñ–Ω–∏ (IAST ‚Üí —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –∑ –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–æ—é),
    –∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –ø–µ—Ä–µ–∫–ª–∞–¥–∏ –∑–∞–ª–∏—à–∞—î –±–µ–∑ –∑–º—ñ–Ω.
    
    –ü—Ä–∏–∫–ª–∞–¥:
    EN: "caitanya ‚Äî of Lord Caitanya; cara·πáa-ambhoja ‚Äî lotus feet"
    UA: "—á–∞—ñ—Ç–∞–Ω–π–∞ ‚Äî –ì–æ—Å–ø–æ–¥–∞ –ß–∞–π—Ç–∞–Ω—å—ó; —á–∞—Ä–∞–ΩÃ£–∞-–∞–º–±–≥–æ–¥–∂–∞ ‚Äî –ª–æ—Ç–æ—Å–æ–≤—ñ —Å—Ç–æ–ø–∏"
    """
    if not synonyms_en:
        return ''
    
    result_pairs = []
    
    for pair in synonyms_en.split(';'):
        pair = pair.strip()
        if not pair:
            continue
        
        if '‚Äî' not in pair and '-' not in pair:
            result_pairs.append(pair)
            continue
        
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ –Ω–∞ —Å–∞–Ω—Å–∫—Ä–∏—Ç—Å—å–∫–∏–π —Ç–µ—Ä–º—ñ–Ω —Ç–∞ –ø–µ—Ä–µ–∫–ª–∞–¥
        parts = pair.split('‚Äî', 1)
        if len(parts) == 2:
            sanskrit_term = parts[0].strip()
            english_meaning = parts[1].strip()
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –¢–Ü–õ–¨–ö–ò —Å–∞–Ω—Å–∫—Ä–∏—Ç—Å—å–∫–∏–π —Ç–µ—Ä–º—ñ–Ω (IAST ‚Üí —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞)
            ukrainian_term = convert_english_to_ukrainian_translit(sanskrit_term)
            ukrainian_term = normalize_diacritics(ukrainian_term)
            
            # –ü–µ—Ä–µ–∫–ª–∞–¥ –∑–∞–ª–∏—à–∞—î–º–æ —è–∫ —î (–≤—ñ–Ω –±—É–¥–µ –∑–∞–º—ñ–Ω–µ–Ω–∏–π –ø–∞—Ä—Å–µ—Ä–æ–º –Ω–∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏–π)
            result_pairs.append(f'{ukrainian_term} ‚Äî {english_meaning}')
        else:
            # –ù–µ–º–∞—î —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫–∞ ‚Äî, –ø—Ä–æ—Å—Ç–æ –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ
            converted = convert_english_to_ukrainian_translit(pair)
            converted = normalize_diacritics(converted)
            result_pairs.append(converted)
    
    return '; '.join(result_pairs)


def restore_diacritics_in_synonyms(synonyms_text: str, transliteration_text: str) -> str:
    """
    –í—ñ–¥–Ω–æ–≤–ª—é—î –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫—É –≤ synonyms_uk –Ω–∞ –æ—Å–Ω–æ–≤—ñ transliteration_uk
    
    Gitabase –º–∞—î –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫—É, –∞–ª–µ –≤–æ–Ω–∞ –≥—É–±–∏—Ç—å—Å—è –ø—Ä–∏ –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—ñ/—ñ–º–ø–æ—Ä—Ç—ñ.
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ transliteration_uk —è–∫ –¥–∂–µ—Ä–µ–ª–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∏—Ö —Ñ–æ—Ä–º –∑ –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–æ—é.
    
    –ü—Ä–∏–∫–ª–∞–¥:
    synonyms: "—á–∞—Ä–∞–∞ ‚Äî –±—ñ–ª—è —Å—Ç—ñ–ø"
    translit: "—á–∞—Ä–∞–ΩÃ£–∞ÃÑ"
    result: "—á–∞—Ä–∞–ΩÃ£–∞ÃÑ ‚Äî –±—ñ–ª—è —Å—Ç—ñ–ø"
    """
    if not synonyms_text or not transliteration_text:
        return synonyms_text
    
    import unicodedata
    
    def remove_combining_marks(text):
        """–í–∏–¥–∞–ª—è—î combining –¥—ñ–∞–∫—Ä–∏—Ç–∏—á–Ω—ñ –∑–Ω–∞–∫–∏ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è"""
        nfd = unicodedata.normalize('NFD', text)
        without = ''.join(ch for ch in nfd if unicodedata.category(ch) != 'Mn')
        return unicodedata.normalize('NFC', without)
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–æ–≤–Ω–∏–∫: —Å–ª–æ–≤–æ_–±–µ–∑_–¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–∏ ‚Üí —Å–ª–æ–≤–æ_–∑_–¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–æ—é
    translit_map = {}
    for word in transliteration_text.replace('-', ' ').replace('  ', ' ').split():
        clean_word = remove_combining_marks(word).lower()
        if clean_word and len(clean_word) > 1:  # –Ü–≥–Ω–æ—Ä—É—î–º–æ –æ–¥–∏–Ω–æ—á–Ω—ñ —Å–∏–º–≤–æ–ª–∏
            translit_map[clean_word] = word
    
    # –û–±—Ä–æ–±–ª—è—î–º–æ synonyms
    result_pairs = []
    for pair in synonyms_text.split(';'):
        pair = pair.strip()
        if not pair:
            continue
            
        if '‚Äî' not in pair:
            result_pairs.append(pair)
            continue
        
        parts = pair.split('‚Äî', 1)
        sanskrit_word = parts[0].strip()
        ukrainian_meaning = parts[1].strip() if len(parts) > 1 else ''
        
        # –î–ª—è —Å–∫–ª–∞–¥–µ–Ω–∏—Ö —Å–ª—ñ–≤ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥: "—á–∞—Ä–∞–∞-–∞–º–±–≥–æ–¥–∂–∞")
        if '-' in sanskrit_word:
            # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–Ω—É —á–∞—Å—Ç–∏–Ω—É –æ–∫—Ä–µ–º–æ
            word_parts = sanskrit_word.split('-')
            restored_parts = []
            for part in word_parts:
                clean_part = remove_combining_marks(part).lower()
                restored_parts.append(translit_map.get(clean_part, part))
            restored_word = '-'.join(restored_parts)
        else:
            # –û–¥–Ω–µ —Å–ª–æ–≤–æ
            clean_word = remove_combining_marks(sanskrit_word).lower()
            restored_word = translit_map.get(clean_word, sanskrit_word)
        
        result_pairs.append(f'{restored_word} ‚Äî {ukrainian_meaning}')
    
    return '; '.join(result_pairs)


def normalize_verse_field(text: str, field_type: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª—ñ–∑—É—î –æ–¥–Ω–µ –ø–æ–ª–µ –≤—ñ—Ä—à—É
    
    field_type: 'sanskrit', 'transliteration', 'transliteration_en', 'synonyms', 'translation', 'commentary'
    """
    if not text:
        return text
    
    # 1. –í–∏–¥–∞–ª—è—î–º–æ mojibake
    result = normalize_mojibake(text)
    
    # 2. –í–∏–¥–∞–ª—è—î–º–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∏ Gitabase
    result = remove_gitabase_artifacts(result)
    
    # 3. –ó–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–∏–ø—É –ø–æ–ª—è
    if field_type == 'sanskrit':
        # –°–∞–Ω—Å–∫—Ä–∏—Ç - –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–∞ + —Ä–æ–∑—Ä–∏–≤–∏ —Ä—è–¥–∫—ñ–≤ –∑–∞ –¥–∞–Ω–¥–∞–º–∏
        result = normalize_diacritics(result)
        result = normalize_sanskrit_line_breaks(result)
    
    elif field_type == 'transliteration_en':
        # –ê–Ω–≥–ª—ñ–π—Å—å–∫–∞ —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—è –∑ Vedabase - –ó–ê–õ–ò–®–ê–Ñ–ú–û –ë–ï–ó –ó–ú–Ü–ù (–æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π IAST)
        # –¢—ñ–ª—å–∫–∏ –≤–∏–¥–∞–ª—è—î–º–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∏
        pass
    
    elif field_type == 'transliteration':
        # –¢—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—è - IAST‚Üí—É–∫—Ä–∞—ó–Ω—Å—å–∫–∞, –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–∞, –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è —Å–ø–æ–ª—É—á–µ–Ω—å, –ë–ï–ó –∑–∞–º—ñ–Ω–∏ —Å–ª—ñ–≤!
        # –í–ê–ñ–õ–ò–í–û: –ù–ï –∑–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ normalize_word_replacements - –∑–∞–ª–∏—à–∞—î–º–æ "–Ω–π–∞" —è–∫ —î
        result = convert_english_to_ukrainian_translit(result)  # IAST ‚Üí —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞!
        result = normalize_diacritics(result)
        result = normalize_transliteration(result)
        # –ù–ï: result = normalize_word_replacements(result)
    
    elif field_type in ['synonyms', 'translation', 'commentary']:
        # –£–∫—Ä–∞—ó–Ω—Å—å–∫—ñ —Ç–µ–∫—Å—Ç–∏ - –≤—Å—ñ –ø—Ä–∞–≤–∏–ª–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
        result = normalize_diacritics(result)  # –í–∏–ø—Ä–∞–≤–ª—è—î —Å–∞–Ω—Å–∫—Ä–∏—Ç—Å—å–∫—É –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫—É
        result = normalize_word_replacements(result)  # —á–∞—ñ—Ç–∞–Ω–π–∞ ‚Üí –ß–∞–π—Ç–∞–Ω—å—è (–Ω–π–∞ ‚Üí –Ω—å—è)
        result = normalize_apostrophe_after_n(result)  # –Ω' ‚Üí –Ω—å
        # –í–∏–ø—Ä–∞–≤–ª—è—î–º–æ —Ç—ñ–ª—å–∫–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ –ø–æ—î–¥–Ω–∞–Ω–Ω—è (—Ç–≥‚Üí—Ç—Ö, –¥–∂–≥‚Üí–¥–∂—Ö, —Ç–æ—â–æ)
        for old, new in TRANSLIT_FIXES.items():
            # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –≤—Å—ñ –ø—Ä–∞–≤–∏–ª–∞ –∑ TRANSLIT_FIXES –≤–∫–ª—é—á–Ω–æ –∑ –¥–∂–≥‚Üí–¥–∂—Ö, –¥–∂–¥–∂–≥‚Üí–¥–∂–¥–∂—Ö
            result = result.replace(old, new)
    
    return result


def normalize_verse(verse: dict) -> dict:
    """–ù–æ—Ä–º–∞–ª—ñ–∑—É—î –≤—Å—ñ –ø–æ–ª—è –æ–¥–Ω–æ–≥–æ –≤—ñ—Ä—à—É"""
    normalized = verse.copy()
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –∫–æ–∂–Ω–µ –ø–æ–ª–µ
    # sanskrit –º—ñ—Å—Ç–∏—Ç—å Bengali/Sanskrit —Ç–µ–∫—Å—Ç (–Ω–∞–∑–≤–∞ –Ω–µ –≤–∞–∂–ª–∏–≤–∞)
    normalized['sanskrit'] = normalize_verse_field(verse.get('sanskrit', ''), 'sanskrit')
    
    # transliteration_en - –ó–ê–õ–ò–®–ê–Ñ–ú–û –ë–ï–ó –ó–ú–Ü–ù (–æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π IAST –∑ Vedabase)
    normalized['transliteration_en'] = normalize_verse_field(verse.get('transliteration_en', ''), 'transliteration_en')
    
    # transliteration_uk - –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ transliteration_en ‚Üí —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞
    if normalized.get('transliteration_en'):
        # –ë–µ—Ä–µ–º–æ IAST –∑ Vedabase —ñ –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—é
        ua_translit = convert_english_to_ukrainian_translit(normalized['transliteration_en'])
        ua_translit = normalize_diacritics(ua_translit)
        normalized['transliteration_uk'] = ua_translit
    else:
        # Fallback: —è–∫—â–æ –Ω–µ–º–∞—î transliteration_en, –±–µ—Ä–µ–º–æ —â–æ —î
        normalized['transliteration_uk'] = normalize_verse_field(verse.get('transliteration_uk', ''), 'transliteration')
    
    # –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç—É (deprecated)
    normalized['transliteration'] = normalized.get('transliteration_uk', '')
    
    # synonyms_en - –∑–∞–ª–∏—à–∞—î–º–æ –ë–ï–ó –ó–ú–Ü–ù (–æ—Ä–∏–≥—ñ–Ω–∞–ª –∑ Vedabase)
    normalized['synonyms_en'] = normalize_verse_field(verse.get('synonyms_en', ''), 'transliteration_en')

    # synonyms_uk - MERGE Vedabase IAST terms + Gitabase UA meanings
    if verse.get('synonyms_uk') and verse.get('synonyms_en'):
        # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–ò–ô –ü–Ü–î–•–Ü–î:
        # –ü–∞—Ä—Å–µ—Ä –ø–æ–≤–µ—Ä—Ç–∞—î –∑ Gitabase –¢–Ü–õ–¨–ö–ò –ó–ù–ê–ß–ï–ù–ù–Ø (–ë–ï–ó —Ç–µ—Ä–º—ñ–Ω—ñ–≤!)
        # –§–æ—Ä–º–∞—Ç Gitabase synonyms_uk: "–≤ —Ç–æ–π —á–∞—Å; –∫—Ä–∞—ó–Ω–∏; –æ–¥–∏–Ω; –º—É—Å—É–ª—å–º–∞–Ω–∏–Ω; ..." (—Ç—ñ–ª—å–∫–∏ –ø–µ—Ä–µ–∫–ª–∞–¥–∏)
        # –§–æ—Ä–º–∞—Ç Vedabase synonyms_en: "hena-kƒÅle ‚Äî at this time; mulukera ‚Äî of the country; ..."
        #
        # –¢—Ä–µ–±–∞ MERGE:
        #   1. –í–∏—Ç—è–≥–Ω—É—Ç–∏ IAST —Ç–µ—Ä–º—ñ–Ω–∏ –∑ Vedabase synonyms_en
        #   2. –ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ —ó—Ö –≤ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—é –∑ –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–æ—é (ISTA2Ukrainian)
        #   3. –í–∑—è—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ Gitabase synonyms_uk (–≤–∂–µ –±–µ–∑ —Ç–µ—Ä–º—ñ–Ω—ñ–≤!)
        #   4. –û–±'—î–¥–Ω–∞—Ç–∏: vedabase_ukrainian_term ‚Äî gitabase_meaning
        
        # Gitabase synonyms_uk –º—ñ—Å—Ç–∏—Ç—å –¢–Ü–õ–¨–ö–ò –ó–ù–ê–ß–ï–ù–ù–Ø (—Ä–æ–∑–¥—ñ–ª–µ–Ω—ñ ;)
        gitabase_meanings = [m.strip() for m in verse['synonyms_uk'].split(';') if m.strip()]
        
        # –†–æ–∑–±–∏–≤–∞—î–º–æ Vedabase pairs –Ω–∞ —Å–ø–∏—Å–æ–∫
        vedabase_pairs = [p.strip() for p in verse['synonyms_en'].split(';') if p.strip()]
        
        result_pairs = []
        for idx, vb_pair in enumerate(vedabase_pairs):
            if '‚Äî' in vb_pair:
                # –í–∏—Ç—è–≥—É—î–º–æ IAST —Ç–µ—Ä–º—ñ–Ω (–ø–µ—Ä—à–∞ —á–∞—Å—Ç–∏–Ω–∞ –¥–æ ‚Äî)
                iast_term = vb_pair.split('‚Äî', 1)[0].strip()
                
                # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ IAST ‚Üí —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞ —Ç—Ä–∞–Ω—Å–ª—ñ—Ç–µ—Ä–∞—Ü—ñ—è –∑ –¥—ñ–∞–∫—Ä–∏—Ç–∏–∫–æ—é
                ua_term = convert_english_to_ukrainian_translit(iast_term)
                
                # –û–±'—î–¥–Ω—É—î–º–æ –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏–º –∑–Ω–∞—á–µ–Ω–Ω—è–º (—è–∫—â–æ —î)
                if idx < len(gitabase_meanings):
                    ua_meaning = gitabase_meanings[idx]
                    result_pairs.append(f'{ua_term} ‚Äî {ua_meaning}')
                else:
                    # Fallback: –Ω–µ–º–∞—î —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–Ω—è, –±–µ—Ä–µ–º–æ –∞–Ω–≥–ª—ñ–π—Å—å–∫–µ
                    en_meaning = vb_pair.split('‚Äî', 1)[1].strip() if '‚Äî' in vb_pair else ''
                    if en_meaning:
                        result_pairs.append(f'{ua_term} ‚Äî {en_meaning}')
        
        if result_pairs:
            normalized['synonyms_uk'] = normalize_verse_field('; '.join(result_pairs), 'synonyms')
        else:
            normalized['synonyms_uk'] = ''
    elif verse.get('synonyms_en'):
        # Fallback: –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –∑ EN —è–∫—â–æ –Ω–µ–º–∞—î UA
        ua_synonyms = convert_synonyms_from_english(verse['synonyms_en'])
        normalized['synonyms_uk'] = normalize_verse_field(ua_synonyms, 'synonyms')
    else:
        normalized['synonyms_uk'] = ''
    normalized['translation_uk'] = normalize_verse_field(verse.get('translation_uk', ''), 'translation')
    normalized['translation_en'] = normalize_verse_field(verse.get('translation_en', ''), 'translation')
    normalized['commentary_uk'] = normalize_verse_field(verse.get('commentary_uk', ''), 'commentary')
    normalized['commentary_en'] = normalize_verse_field(verse.get('commentary_en', ''), 'commentary')
    
    return normalized


def normalize_parsed_data(data: dict) -> dict:
    """
    –ù–æ—Ä–º–∞–ª—ñ–∑—É—î –ø–æ–≤–Ω–∏–π parsed JSON
    
    Args:
        data: dict –∑ –∫–ª—é—á–∞–º–∏ 'verses' —Ç–∞ 'summary'
    
    Returns:
        normalized dict
    """
    normalized_verses = []
    
    for verse in data.get('verses', []):
        normalized = normalize_verse(verse)
        normalized_verses.append(normalized)
    
    return {
        'verses': normalized_verses,
        'summary': data.get('summary', {}),
    }


# ============================================================================
# CLI
# ============================================================================

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python3 pre_import_normalizer.py <input.json> [output.json]")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else input_file.replace('.json', '_normalized.json')
    
    print(f"üìñ –ß–∏—Ç–∞—é: {input_file}")
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"üîß –ù–æ—Ä–º–∞–ª—ñ–∑—É—é {len(data.get('verses', []))} –≤—ñ—Ä—à—ñ–≤...")
    normalized = normalize_parsed_data(data)
    
    print(f"üíæ –ó–±–µ—Ä—ñ–≥–∞—é: {output_file}")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(normalized, f, ensure_ascii=False, indent=2)
    
    print("‚úÖ –ì–æ—Ç–æ–≤–æ!")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total = len(normalized['verses'])
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  –í—Å—å–æ–≥–æ –≤—ñ—Ä—à—ñ–≤: {total}")
    
    # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ –∑–∞–ø–æ–≤–Ω–µ–Ω–∏—Ö –ø–æ–ª—ñ–≤
    fields = ['sanskrit', 'transliteration', 'synonyms_uk', 'translation_uk', 'commentary_uk']
    for field in fields:
        filled = sum(1 for v in normalized['verses'] if v.get(field))
        print(f"  {field}: {filled}/{total}")
