#!/usr/bin/env python3
"""
–Ü–º–ø–æ—Ä—Ç ≈örƒ´mad-BhƒÅgavatam –∑ EPUB ‚Üí Supabase

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
    python3 import_sb_epub.py --epub UK_SB_3_epub_r1.epub --canto 3 --chapters 17 --dry-run
    python3 import_sb_epub.py --epub UK_SB_3_epub_r1.epub --canto 3 --chapters 17-33
"""

import argparse
import re
import os
import sys
from dataclasses import dataclass
from typing import List, Optional, Tuple

import ebooklib
from ebooklib import epub
from bs4 import BeautifulSoup
import requests
from supabase import create_client

# Supabase configuration
SUPABASE_URL = os.getenv('SUPABASE_URL', '')
SUPABASE_KEY = os.getenv('SUPABASE_SERVICE_KEY', '')

# Vedabase API (–∑ User-Agent —è–∫ –≤ cc_importer_final.py)
VEDABASE_SESSION = requests.Session()
VEDABASE_SESSION.headers.update({
    'User-Agent': 'vedavoice-sb-importer/1.0 (+https://vedavoice.org)'
})


@dataclass
class ParsedVerse:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –≤—ñ—Ä—à–∞ –∑ EPUB"""
    verse_number: str
    sanskrit: str              # –ó EPUB (Devanagari)
    transliteration_ua: str    # –ó EPUB (IAST —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é)
    synonyms_ua: str           # –ó EPUB ("–ü–æ—Å–ª—ñ–≤–Ω–∏–π –ø–µ—Ä–µ–∫–ª–∞–¥")
    translation_ua: str        # –ó EPUB ("–ü–µ—Ä–µ–∫–ª–∞–¥")
    commentary_ua: str         # –ó EPUB ("–ü–æ—è—Å–Ω–µ–Ω–Ω—è")
    transliteration_en: str    # –ó Vedabase (IAST)
    synonyms_en: str           # –ó Vedabase (IAST)
    translation_en: str        # –ó Vedabase
    commentary_en: str         # –ó Vedabase


@dataclass
class ParsedChapter:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –≥–ª–∞–≤–∏"""
    canto_number: int
    chapter_number: int
    title_ua: str
    title_en: str
    verses: List[ParsedVerse]


# –°–ª–æ–≤–Ω–∏–∫ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏—Ö –Ω–∞–∑–≤ –≥–ª–∞–≤ (ASCII apostrophes; apostrophes normalized in extract function)
CHAPTER_NAMES_UA = {
    '–ø–µ—Ä—à–∞': 1, '–¥—Ä—É–≥–∞': 2, '—Ç—Ä–µ—Ç—è': 3, '—á–µ—Ç–≤–µ—Ä—Ç–∞': 4, "–ø'—è—Ç–∞": 5,
    '—à–æ—Å—Ç–∞': 6, '—Å—å–æ–º–∞': 7, '–≤–æ—Å—å–º–∞': 8, "–¥–µ–≤'—è—Ç–∞": 9, '–¥–µ—Å—è—Ç–∞': 10,
    '–æ–¥–∏–Ω–∞–¥—Ü—è—Ç–∞': 11, '–¥–≤–∞–Ω–∞–¥—Ü—è—Ç–∞': 12, '—Ç—Ä–∏–Ω–∞–¥—Ü—è—Ç–∞': 13, '—á–æ—Ç–∏—Ä–Ω–∞–¥—Ü—è—Ç–∞': 14,
    "–ø'—è—Ç–Ω–∞–¥—Ü—è—Ç–∞": 15, '—à—ñ—Å—Ç–Ω–∞–¥—Ü—è—Ç–∞': 16, '—Å—ñ–º–Ω–∞–¥—Ü—è—Ç–∞': 17, '–≤—ñ—Å—ñ–º–Ω–∞–¥—Ü—è—Ç–∞': 18,
    "–¥–µ–≤'—è—Ç–Ω–∞–¥—Ü—è—Ç–∞": 19, '–¥–≤–∞–¥—Ü—è—Ç–∞': 20,
    # Compound forms with "–¨" (–¥–≤–∞–¥—Ü—è—Ç—å)
    '–¥–≤–∞–¥—Ü—è—Ç—å –ø–µ—Ä—à–∞': 21, '–¥–≤–∞–¥—Ü—è—Ç—å –¥—Ä—É–≥–∞': 22, '–¥–≤–∞–¥—Ü—è—Ç—å —Ç—Ä–µ—Ç—è': 23,
    '–¥–≤–∞–¥—Ü—è—Ç—å —á–µ—Ç–≤–µ—Ä—Ç–∞': 24, "–¥–≤–∞–¥—Ü—è—Ç—å –ø'—è—Ç–∞": 25, '–¥–≤–∞–¥—Ü—è—Ç—å —à–æ—Å—Ç–∞': 26,
    '–¥–≤–∞–¥—Ü—è—Ç—å —Å—å–æ–º–∞': 27, '–¥–≤–∞–¥—Ü—è—Ç—å –≤–æ—Å—å–º–∞': 28, "–¥–≤–∞–¥—Ü—è—Ç—å –¥–µ–≤'—è—Ç–∞": 29,
    # Compound forms with "–ê" (–¥–≤–∞–¥—Ü—è—Ç–∞) - as they appear in EPUB
    '–¥–≤–∞–¥—Ü—è—Ç–∞ –ø–µ—Ä—à–∞': 21, '–¥–≤–∞–¥—Ü—è—Ç–∞ –¥—Ä—É–≥–∞': 22, '–¥–≤–∞–¥—Ü—è—Ç–∞ —Ç—Ä–µ—Ç—è': 23,
    '–¥–≤–∞–¥—Ü—è—Ç–∞ —á–µ—Ç–≤–µ—Ä—Ç–∞': 24, "–¥–≤–∞–¥—Ü—è—Ç–∞ –ø'—è—Ç–∞": 25, '–¥–≤–∞–¥—Ü—è—Ç–∞ —à–æ—Å—Ç–∞': 26,
    '–¥–≤–∞–¥—Ü—è—Ç–∞ —Å—å–æ–º–∞': 27, '–¥–≤–∞–¥—Ü—è—Ç–∞ –≤–æ—Å—å–º–∞': 28, "–¥–≤–∞–¥—Ü—è—Ç–∞ –¥–µ–≤'—è—Ç–∞": 29,
    # 30+
    '—Ç—Ä–∏–¥—Ü—è—Ç–∞': 30,
    '—Ç—Ä–∏–¥—Ü—è—Ç—å –ø–µ—Ä—à–∞': 31, '—Ç—Ä–∏–¥—Ü—è—Ç—å –¥—Ä—É–≥–∞': 32, '—Ç—Ä–∏–¥—Ü—è—Ç—å —Ç—Ä–µ—Ç—è': 33,
    '—Ç—Ä–∏–¥—Ü—è—Ç–∞ –ø–µ—Ä—à–∞': 31, '—Ç—Ä–∏–¥—Ü—è—Ç–∞ –¥—Ä—É–≥–∞': 32, '—Ç—Ä–∏–¥—Ü—è—Ç–∞ —Ç—Ä–µ—Ç—è': 33,
}


def extract_chapter_number(title: str) -> int:
    """–í–∏—Ç—è–≥—É—î –Ω–æ–º–µ—Ä –≥–ª–∞–≤–∏ –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Ç–∏–ø—É '–°–Ü–ú–ù–ê–î–¶–Ø–¢–ê'"""
    normalized = title.lower().strip()

    # Normalize all apostrophe variants to ASCII apostrophe
    # U+2019 ('), U+0027 ('), U+02BC ( º) ‚Üí '
    normalized = normalized.replace('\u2019', "'").replace('\u02BC', "'")

    # Sort by length DESC to match longer names first
    # –¶–µ –≤–∞–∂–ª–∏–≤–æ –±–æ "–≤—ñ—Å—ñ–º–Ω–∞–¥—Ü—è—Ç–∞" –º—ñ—Å—Ç–∏—Ç—å "—Å—ñ–º–Ω–∞–¥—Ü—è—Ç–∞" —è–∫ –ø—ñ–¥—Ä—è–¥–æ–∫
    for name, num in sorted(CHAPTER_NAMES_UA.items(), key=lambda x: len(x[0]), reverse=True):
        if name in normalized:
            return num

    # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, —Å–ø—Ä–æ–±—É–≤–∞—Ç–∏ —á–∏—Å–ª–∞
    match = re.search(r'\d+', title)
    return int(match.group()) if match else 0


def is_sanskrit_text(text: str) -> bool:
    """–í–∏–∑–Ω–∞—á–∞—î, —á–∏ –º—ñ—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç Devanagari –∞–±–æ Bengali"""
    return bool(re.search(r'[\u0900-\u097F\u0980-\u09FF‡•§‡••]', text))


def normalize_text(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª—ñ–∑—É—î —Ç–µ–∫—Å—Ç: –ø—Ä–∏–±–∏—Ä–∞—î –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏, –æ–±'—î–¥–Ω—É—î —Ä—è–¥–∫–∏"""
    # –ó–∞–º—ñ–Ω–∏—Ç–∏ multiple spaces –Ω–∞ –æ–¥–∏–Ω
    text = re.sub(r'\s+', ' ', text)
    # –ü—Ä–∏–±—Ä–∞—Ç–∏ –ø—Ä–æ–±—ñ–ª–∏ –Ω–∞ –ø–æ—á–∞—Ç–∫—É/–∫—ñ–Ω—Ü—ñ
    text = text.strip()
    # –ü—Ä–∏–±—Ä–∞—Ç–∏ –ø—Ä–æ–±—ñ–ª–∏ –ø–µ—Ä–µ–¥ —Ä–æ–∑–¥—ñ–ª–æ–≤–∏–º–∏ –∑–Ω–∞–∫–∞–º–∏
    text = re.sub(r'\s+([.,;:!?])', r'\1', text)
    return text


def parse_verse_from_html(verse_html: str, verse_number: str) -> ParsedVerse:
    """
    –ü–∞—Ä—Å–∏—Ç—å –≤—ñ—Ä—à –∑ HTML –±–ª–æ–∫—É

    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ EPUB:
    1. Sanskrit (Devanagari) - –±–µ—Ä–µ–º–æ
    2. Transliteration UA (IAST —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é) - –±–µ—Ä–µ–º–æ
    3. "–ü–æ—Å–ª—ñ–≤–Ω–∏–π –ø–µ—Ä–µ–∫–ª–∞–¥" - synonyms UA - –±–µ—Ä–µ–º–æ
    4. "–ü–µ—Ä–µ–∫–ª–∞–¥" - translation UA - –±–µ—Ä–µ–º–æ
    5. "–ü–æ—è—Å–Ω–µ–Ω–Ω—è" - commentary UA - –±–µ—Ä–µ–º–æ
    """
    lines = [line.strip() for line in verse_html.split('\n') if line.strip()]

    sanskrit = ''
    transliteration_ua = ''
    synonyms_ua = ''
    translation_ua = ''
    commentary_ua = ''

    state = 'sanskrit'  # sanskrit -> translit -> synonyms -> translation -> commentary

    for line in lines:
        # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –º–∞—Ä–∫–µ—Ä–∏ –≤—ñ—Ä—à—ñ–≤
        if re.match(r'^–í—ñ—Ä—à\s+\d+', line, re.I):
            continue

        # –ú–∞—Ä–∫–µ—Ä–∏ —Å–µ–∫—Ü—ñ–π
        if re.match(r'^–ü–æ—Å–ª—ñ–≤–Ω–∏–π –ø–µ—Ä–µ–∫–ª–∞–¥', line, re.I):
            state = 'synonyms'
            continue
        if re.match(r'^–ü–µ—Ä–µ–∫–ª–∞–¥$', line, re.I):
            state = 'translation'
            continue
        if re.match(r'^–ü–æ—è—Å–Ω–µ–Ω–Ω—è', line, re.I):
            state = 'commentary'
            continue

        # –ó–±–∏—Ä–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
        if state == 'sanskrit' and is_sanskrit_text(line):
            sanskrit += (' ' if sanskrit else '') + line
        elif state == 'sanskrit' and not is_sanskrit_text(line):
            # –ü—ñ—Å–ª—è Sanskrit –π–¥–µ transliteration
            state = 'translit'
            transliteration_ua += line
        elif state == 'translit':
            transliteration_ua += ' ' + line
        elif state == 'synonyms':
            synonyms_ua += (' ' if synonyms_ua else '') + line
        elif state == 'translation':
            translation_ua += (' ' if translation_ua else '') + line
        elif state == 'commentary':
            commentary_ua += (' ' if commentary_ua else '') + line

    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
    sanskrit = normalize_text(sanskrit)
    transliteration_ua = normalize_text(transliteration_ua)
    synonyms_ua = normalize_text(synonyms_ua)
    translation_ua = normalize_text(translation_ua)
    commentary_ua = normalize_text(commentary_ua)

    return ParsedVerse(
        verse_number=verse_number,
        sanskrit=sanskrit,
        transliteration_ua=transliteration_ua,
        synonyms_ua=synonyms_ua,
        translation_ua=translation_ua,
        commentary_ua=commentary_ua,
        transliteration_en='',  # –ë—É–¥–µ –∑ Vedabase
        synonyms_en='',         # –ë—É–¥–µ –∑ Vedabase
        translation_en='',      # –ë—É–¥–µ –∑ Vedabase
        commentary_en='',       # –ë—É–¥–µ –∑ Vedabase
    )


def parse_chapter_from_epub(book: epub.EpubBook, chapter_file: str, canto_number: int) -> Optional[ParsedChapter]:
    """–ü–∞—Ä—Å–∏—Ç—å –æ–¥–Ω—É –≥–ª–∞–≤—É –∑ EPUB"""
    # –ó–Ω–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç
    item = None
    for doc in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):
        if doc.file_name == chapter_file:
            item = doc
            break

    if not item:
        print(f"‚ùå Chapter file not found: {chapter_file}")
        return None

    # –†–æ–∑–±—ñ—Ä HTML
    soup = BeautifulSoup(item.get_content(), 'html.parser')
    text = soup.get_text()

    # –ó–Ω–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤–∏ (–¥–æ–ø—É—Å–∫–∞—î–º–æ –≤—Å—ñ —Å–∏–º–≤–æ–ª–∏ –¥–æ –∫—ñ–Ω—Ü—è —Ä—è–¥–∫–∞)
    title_match = re.search(r'–≥–ª–∞–≤–∞\s+(.+?)(?:\n|$)', text, re.I)
    if not title_match:
        print(f"‚ùå Chapter title not found in {chapter_file}")
        return None

    title_ua = title_match.group(1).strip().upper()
    chapter_number = extract_chapter_number(title_ua)

    print(f"üìñ Found chapter: {chapter_number} - {title_ua}")

    # –†–æ–∑–±–∏—Ç–∏ –Ω–∞ –≤—ñ—Ä—à—ñ
    verse_pattern = re.compile(r'–í—ñ—Ä—à\s+(\d+(?:\s*[-‚Äì‚Äî]\s*\d+)?)', re.I)
    verse_matches = list(verse_pattern.finditer(text))

    verses = []
    for i, match in enumerate(verse_matches):
        verse_number = match.group(1).replace(' ', '')  # "22-23" –∞–±–æ "1"
        start_pos = match.end()
        end_pos = verse_matches[i + 1].start() if i < len(verse_matches) - 1 else len(text)

        verse_html = text[start_pos:end_pos]

        try:
            verse = parse_verse_from_html(verse_html, verse_number)
            verses.append(verse)
            print(f"‚úÖ Parsed verse {verse_number}")
        except Exception as e:
            print(f"‚ùå Failed to parse verse {verse_number}: {e}")

    return ParsedChapter(
        canto_number=canto_number,
        chapter_number=chapter_number,
        title_ua=title_ua,
        title_en='',  # –ë—É–¥–µ –∑ Vedabase
        verses=verses,
    )


def fetch_vedabase_verse(canto: int, chapter: int, verse: str) -> Optional[dict]:
    """–û—Ç—Ä–∏–º—É—î –¥–∞–Ω—ñ –≤—ñ—Ä—à–∞ –∑ Vedabase API"""
    try:
        url = f"https://vedabase.io/en/library/sb/{canto}/{chapter}/{verse}/?format=json"
        response = VEDABASE_SESSION.get(url, timeout=10)

        if response.status_code == 200:
            data = response.json()
            return {
                'transliteration_en': data.get('transliteration', ''),
                'synonyms_en': data.get('synonyms', ''),
                'translation_en': data.get('translation', ''),
                'commentary_en': data.get('purport', ''),
                'title_en': data.get('chapter_title', ''),
            }
        else:
            print(f"  ‚ö†Ô∏è  Vedabase returned {response.status_code} for {canto}.{chapter}.{verse}")
            return None
    except Exception as e:
        print(f"  ‚ùå Error fetching from Vedabase: {e}")
        return None


def enrich_with_vedabase(chapters: List[ParsedChapter], skip_vedabase: bool = False) -> None:
    """–î–æ–¥–∞—î –∞–Ω–≥–ª—ñ–π—Å—å–∫—ñ –¥–∞–Ω—ñ –∑ Vedabase"""
    if skip_vedabase:
        print("‚è≠Ô∏è  Skipping Vedabase enrichment")
        return

    print("\nüåê Fetching English data from Vedabase...")

    for chapter in chapters:
        print(f"  üìñ Chapter {chapter.chapter_number}:")

        for verse in chapter.verses:
            # –û–±—Ä–æ–±–∫–∞ composite verses (e.g., "22-23")
            verse_nums = verse.verse_number.split('-')
            verse_num = verse_nums[0]  # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π –Ω–æ–º–µ—Ä

            print(f"    üîÑ Fetching verse {verse.verse_number}...", end=' ')

            vedabase_data = fetch_vedabase_verse(
                chapter.canto_number,
                chapter.chapter_number,
                verse_num
            )

            if vedabase_data:
                verse.transliteration_en = vedabase_data['transliteration_en']
                verse.synonyms_en = vedabase_data['synonyms_en']
                verse.translation_en = vedabase_data['translation_en']
                verse.commentary_en = vedabase_data['commentary_en']

                if not chapter.title_en and vedabase_data['title_en']:
                    chapter.title_en = vedabase_data['title_en']

                print("‚úÖ")
            else:
                print("‚ùå")


def save_to_supabase(chapters: List[ParsedChapter], dry_run: bool = False) -> None:
    """–ó–±–µ—Ä—ñ–≥–∞—î –≥–ª–∞–≤–∏ —Ç–∞ –≤—ñ—Ä—à—ñ –≤ Supabase"""
    if dry_run:
        print("\nüîç Dry run - skipping database save")
        return

    if not SUPABASE_URL or not SUPABASE_KEY:
        print("‚ùå Missing SUPABASE_URL or SUPABASE_SERVICE_KEY environment variables")
        return

    print("\nüíæ Saving to Supabase...")

    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

    for chapter in chapters:
        print(f"  üìñ Saving chapter {chapter.chapter_number}...")

        # TODO: Implement Supabase save logic
        # 1. Get or create canto
        # 2. Get or create chapter
        # 3. Insert verses

        print(f"  ‚úÖ Saved chapter {chapter.chapter_number}")


def print_summary(chapters: List[ParsedChapter]) -> None:
    """–í–∏–≤–æ–¥–∏—Ç—å –ø—ñ–¥—Å—É–º–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥—É"""
    print("\n" + "="*60)
    print("üìä Import Summary:")
    print("="*60)

    for chapter in chapters:
        print(f"\nüìñ Chapter {chapter.chapter_number}: {chapter.title_ua}")
        if chapter.title_en:
            print(f"   EN: {chapter.title_en}")
        print(f"   Verses: {len(chapter.verses)}")

        for verse in chapter.verses[:3]:  # Show first 3 verses
            print(f"   ‚Ä¢ {verse.verse_number}: {verse.translation_ua[:100]}...")


def parse_chapter_range(chapters_arg: str) -> Tuple[int, int]:
    """–ü–∞—Ä—Å–∏—Ç—å –¥—ñ–∞–ø–∞–∑–æ–Ω –≥–ª–∞–≤ –∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞: '17' –∞–±–æ '17-33'"""
    if '-' in chapters_arg:
        start, end = chapters_arg.split('-')
        return int(start), int(end)
    else:
        num = int(chapters_arg)
        return num, num


def find_chapter_file(book: epub.EpubBook, chapter_number: int) -> Optional[str]:
    """–ó–Ω–∞—Ö–æ–¥–∏—Ç—å XHTML —Ñ–∞–π–ª –≥–ª–∞–≤–∏ –∑–∞ —ó—ó –Ω–æ–º–µ—Ä–æ–º"""
    # –§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—ñ–≤: UKS317XT.xhtml –¥–ª—è –≥–ª–∞–≤–∏ 17
    # UKS3 + chapter_number (2 digits) + XT.xhtml
    filename = f"UKS3{chapter_number:02d}XT.xhtml"

    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏, —á–∏ —ñ—Å–Ω—É—î —Ñ–∞–π–ª
    for item in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):
        if item.file_name == filename:
            return filename

    return None


def main():
    parser = argparse.ArgumentParser(
        description='Import ≈örƒ´mad-BhƒÅgavatam from EPUB to Supabase'
    )
    parser.add_argument('--epub', required=True, help='Path to EPUB file')
    parser.add_argument('--canto', type=int, required=True, help='Canto number (e.g., 3)')
    parser.add_argument('--chapters', required=True, help='Chapter number or range (e.g., 17 or 17-33)')
    parser.add_argument('--dry-run', action='store_true', help='Parse but do not save to database')
    parser.add_argument('--skip-vedabase', action='store_true', help='Skip fetching English data from Vedabase')

    args = parser.parse_args()

    # –ß–∏—Ç–∞–Ω–Ω—è EPUB
    print(f"üìö Reading EPUB: {args.epub}")
    try:
        book = epub.read_epub(args.epub)
    except Exception as e:
        print(f"‚ùå Failed to read EPUB: {e}")
        sys.exit(1)

    # –ü–∞—Ä—Å–∏–Ω–≥ –¥—ñ–∞–ø–∞–∑–æ–Ω—É –≥–ª–∞–≤
    start_chapter, end_chapter = parse_chapter_range(args.chapters)
    print(f"üîç Parsing chapters {start_chapter}-{end_chapter} from canto {args.canto}...")

    # –ü–∞—Ä—Å–∏–Ω–≥ –≥–ª–∞–≤
    chapters = []
    for chapter_num in range(start_chapter, end_chapter + 1):
        chapter_file = find_chapter_file(book, chapter_num)

        if not chapter_file:
            print(f"‚ö†Ô∏è  Chapter {chapter_num} not found in EPUB")
            continue

        chapter = parse_chapter_from_epub(book, chapter_file, args.canto)
        if chapter:
            chapters.append(chapter)

    if not chapters:
        print("‚ùå No chapters found")
        sys.exit(1)

    print(f"\n‚úÖ Found {len(chapters)} chapters")

    # –ó–±–∞–≥–∞—á–µ–Ω–Ω—è –∑ Vedabase
    enrich_with_vedabase(chapters, args.skip_vedabase)

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –ë–î
    save_to_supabase(chapters, args.dry_run)

    # –ü—ñ–¥—Å—É–º–æ–∫
    print_summary(chapters)

    print("\n‚úÖ Import complete!")


if __name__ == '__main__':
    main()
